{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7594ad37-5422-4695-b1f3-5f10b631f5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def segment_lesion_auto(image_rgb, min_lesion_frac=0.005):\n",
    "    gray = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    gray = clahe.apply(gray)\n",
    "\n",
    "    inv = 255 - gray\n",
    "    _, th = cv2.threshold(inv, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    th = cv2.medianBlur(th, 5)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))\n",
    "    th = cv2.morphologyEx(th, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "    th = cv2.morphologyEx(th, cv2.MORPH_OPEN,  kernel, iterations=1)\n",
    "\n",
    "    num, labels = cv2.connectedComponents(th)\n",
    "    if num > 1:\n",
    "        areas = [np.sum(labels == i) for i in range(1, num)]\n",
    "        max_lbl = 1 + int(np.argmax(areas))\n",
    "        mask = (labels == max_lbl)\n",
    "    else:\n",
    "        mask = th.astype(bool)\n",
    "\n",
    "    if mask.mean() < min_lesion_frac:\n",
    "        mask[:] = False\n",
    "    return mask\n",
    "\n",
    "def mask_by_region_auto(image_rgb, lesion_ratio=0.6, bg_ratio=0.4, mask_value=(0,0,0), seed=None):\n",
    "    \"\"\"\n",
    "    自動找病灶，再將病灶區遮蔽 lesion_ratio、非病灶區遮蔽 bg_ratio。\n",
    "    回傳 (masked_img, lesion_mask_bool, masked_pixels_uint8)\n",
    "    \"\"\"\n",
    "    assert image_rgb.ndim == 3 and image_rgb.shape[2] == 3, \"image_rgb must be HxWx3 RGB.\"\n",
    "    H, W, _ = image_rgb.shape\n",
    "    lesion_mask = segment_lesion_auto(image_rgb)  # Bool mask\n",
    "\n",
    "    lesion_idx = np.flatnonzero(lesion_mask.ravel())\n",
    "    bg_idx = np.flatnonzero(~lesion_mask.ravel())\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n_lesion = int(min(len(lesion_idx), max(0, round(lesion_ratio * len(lesion_idx)))))\n",
    "    n_bg     = int(min(len(bg_idx),     max(0, round(bg_ratio     * len(bg_idx)))))\n",
    "\n",
    "    pick_lesion = rng.choice(lesion_idx, size=n_lesion, replace=False) if n_lesion > 0 else np.array([], dtype=int)\n",
    "    pick_bg     = rng.choice(bg_idx,     size=n_bg,     replace=False) if n_bg > 0     else np.array([], dtype=int)\n",
    "    pick_all    = np.concatenate([pick_lesion, pick_bg])\n",
    "\n",
    "    masked_pixels = np.zeros((H * W,), dtype=np.uint8)\n",
    "    if pick_all.size > 0:\n",
    "        masked_pixels[pick_all] = 255\n",
    "    masked_pixels = masked_pixels.reshape(H, W)\n",
    "\n",
    "    masked_img = image_rgb.copy()\n",
    "    if isinstance(mask_value, (tuple, list)) and len(mask_value) == 3:\n",
    "        masked_img.reshape(-1, 3)[pick_all] = mask_value\n",
    "    else:\n",
    "        masked_img.reshape(-1, 3)[pick_all] = (mask_value, mask_value, mask_value)\n",
    "\n",
    "    return masked_img, lesion_mask, masked_pixels\n",
    "\n",
    "\n",
    "def show_triplet(image_path):\n",
    "    bgr = cv2.imread(image_path)\n",
    "    rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    masked_img, lesion_mask, masked_pixels = mask_by_region_auto(\n",
    "        rgb, lesion_ratio=0.8, bg_ratio=0.1\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.subplot(1,3,1); plt.imshow(rgb); plt.title(\"Original\"); plt.axis(\"off\")\n",
    "    plt.subplot(1,3,2); plt.imshow(lesion_mask, cmap=\"gray\"); plt.title(\"Lesion Mask\"); plt.axis(\"off\")\n",
    "    plt.subplot(1,3,3); plt.imshow(masked_img); plt.title(\"Masked (L80% / BG10%)\"); plt.axis(\"off\")\n",
    "    plt.tight_layout(); plt.savefig(\"./tt.png\", dpi=800, bbox_inches=\"tight\"); plt.show()\n",
    "\n",
    "show_triplet(\"./t.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dc5f71-e18f-44e4-89d7-cde67c2c9c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"./t.jpg\")\n",
    "plt.figure(figsize=(12, 4))\n",
    "ax = plt.subplot(131)\n",
    "ax.axis(\"off\")\n",
    "plt.imshow(img[:, :, ::-1])\n",
    "\n",
    "ax = plt.subplot(132)\n",
    "ax.axis(\"off\")\n",
    "blurred = cv2.bilateralFilter(img, d=5, sigmaColor=25, sigmaSpace=25)\n",
    "plt.imshow(blurred[:, :, ::-1])\n",
    "\n",
    "ax = plt.subplot(133)\n",
    "ax.axis(\"off\")\n",
    "blurred = cv2.bilateralFilter(img, d=9, sigmaColor=75, sigmaSpace=75)\n",
    "plt.imshow(blurred[:, :, ::-1])\n",
    "\n",
    "plt.savefig(\"blue_show.png\", dpi=400, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df2faff-cbbd-4496-a854-e4f4c5509623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from tqdm import tqdm\n",
    "\n",
    "dataset_path = \"/home/hank52052/Dataset/isic/HAM10000/yolo_format/train/\"\n",
    "target_count = 6705  \n",
    "\n",
    "def gamma_adjust_red_channel(image, **kwargs):\n",
    "    image = image.astype(np.int32)\n",
    "    image[:, :, 2] = np.clip(image[:, :, 2] + np.random.randint(-30, 30), 0, 255)\n",
    "    return image.astype(np.uint8)\n",
    "\n",
    "augmentation_methods = [\n",
    "    A.HorizontalFlip(p=1.0),\n",
    "    A.VerticalFlip(p=1.0),\n",
    "    A.Rotate(limit=(-30, 30), p=1.0),\n",
    "    A.Affine(scale=(1.0, 1.3), translate_percent=(0.0, 0.1), rotate=(-30, 30), shear=(-10, 10), p=1.0),\n",
    "    A.Resize(height=300, width=300, p=1.0),  \n",
    "    A.RandomCrop(height=256, width=256, p=1.0), \n",
    "    A.Perspective(scale=(0.05, 0.1), p=1.0),\n",
    "    A.ElasticTransform(alpha=1.0, sigma=50, p=1.0),\n",
    "    A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=10, p=1.0),\n",
    "    A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=1.0),\n",
    "    A.Lambda(image=gamma_adjust_red_channel, p=1.0),  \n",
    "    A.MotionBlur(blur_limit=(3, 7), p=1.0),\n",
    "]\n",
    "\n",
    "class_counts = {\n",
    "    \"AKIEC\": 327,\n",
    "    \"BCC\": 514,\n",
    "    \"BKL\": 1099,\n",
    "    \"DF\": 115,\n",
    "    \"MEL\": 1113,\n",
    "    \"NV\": 6705,\n",
    "    \"VASC\": 142\n",
    "}\n",
    "\n",
    "for class_name, count in tqdm(class_counts.items(), desc=\"Data Augmentation\"):\n",
    "    class_dir = os.path.join(dataset_path, class_name)\n",
    "    images = [f for f in os.listdir(class_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "\n",
    "    if count >= target_count:\n",
    "        continue\n",
    "\n",
    "    while len(images) < target_count:\n",
    "        img_name = random.choice(images) \n",
    "        img_path = os.path.join(class_dir, img_name)\n",
    "        \n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        num_transforms = random.randint(2, 4)\n",
    "        selected_transforms = random.sample(augmentation_methods, num_transforms)\n",
    "        augmentation = A.Compose(selected_transforms)\n",
    "\n",
    "        augmented = augmentation(image=image)['image']\n",
    "\n",
    "        new_img_name = f\"aug_{len(images)}_{img_name}\"\n",
    "        new_img_path = os.path.join(class_dir, new_img_name)\n",
    "        cv2.imwrite(new_img_path, cv2.cvtColor(augmented, cv2.COLOR_RGB2BGR))\n",
    "        \n",
    "        images.append(new_img_name)  # 更新列表\n",
    "\n",
    "print(\"✅ 影像增強完成，每個類別都擴增到 6705 張！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad22be9b-83a1-4ff0-aca6-c465ac50cd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import textwrap\n",
    "\n",
    "\n",
    "def generate_diagonal_cross_kernel(size=13):\n",
    "    kernel = np.zeros((size, size), dtype=np.uint8)\n",
    "    center = size // 2\n",
    "\n",
    "    for i in range(0, size, 2):\n",
    "        kernel[center, i] = 1\n",
    "        kernel[i, center] = 1\n",
    "\n",
    "    for i in range(0, size, 2):\n",
    "        kernel[i, i] = 1\n",
    "        kernel[i, size - 1 - i] = 1\n",
    "    \n",
    "    kernel[center, center - 1:center + 2] = 0\n",
    "    kernel[center - 1:center + 2, center] = 0\n",
    "    kernel[center - 1, center - 1] = 0\n",
    "    kernel[center - 1, center + 1] = 0\n",
    "    kernel[center + 1, center - 1] = 0\n",
    "    kernel[center + 1, center + 1] = 0\n",
    "\n",
    "    return kernel\n",
    "\n",
    "kernel_struct = generate_diagonal_cross_kernel(13)\n",
    "\n",
    "img_path = \"../../Dataset/isic/HAM10000/images/ISIC_0024748.jpg\" \n",
    "skin_image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "top_hat = cv2.morphologyEx(skin_image, cv2.MORPH_BLACKHAT, kernel_struct)\n",
    "_, binary_mask = cv2.threshold(top_hat, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "kernel_open = cv2.getStructuringElement(cv2.MORPH_CROSS, (9,9))\n",
    "binary_mask_cleaned = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel_open)\n",
    "\n",
    "image = cv2.imread(img_path)\n",
    "\n",
    "image = cv2.inpaint(image, binary_mask_cleaned, inpaintRadius=5, flags=cv2.INPAINT_TELEA)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "augmentation_methods = [\n",
    "    A.HorizontalFlip(p=1.0),\n",
    "    A.VerticalFlip(p=1.0),\n",
    "    A.Rotate(limit=(-30, 30), p=1.0),\n",
    "    A.Affine(scale=(1.0, 1.3), translate_percent=(0.0, 0.1), rotate=(-30, 30), shear=(-10, 10), p=1.0),\n",
    "    A.Perspective(scale=(0.05, 0.1), p=1.0),\n",
    "    A.ElasticTransform(alpha=1.0, sigma=50, p=1.0),\n",
    "    A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=10, p=1.0),\n",
    "    A.MotionBlur(blur_limit=(3, 7), p=1.0),\n",
    "    A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=1.0)\n",
    "]\n",
    "\n",
    "\n",
    "augmented_images = [image] \n",
    "titles = [\"Original\"]\n",
    "\n",
    "for _ in range(8):\n",
    "    num_transforms = random.randint(2, 4) \n",
    "    selected_transforms = random.sample(augmentation_methods, num_transforms)\n",
    "    augmentation = A.Compose(selected_transforms)\n",
    "\n",
    "    augmented = augmentation(image=image)[\"image\"]\n",
    "    augmented_images.append(augmented)\n",
    "\n",
    "    transform_names = [str(t).split(\"(\")[0] for t in selected_transforms]\n",
    "    formatted_title = \"\\n\".join(textwrap.wrap(\", \".join(transform_names), width=25))  \n",
    "    titles.append(formatted_title)\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n",
    "\n",
    "for ax, img, title in zip(axes.ravel(), augmented_images, titles):\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(title, fontsize=12, pad=10)  \n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./aug_show.png\", dpi=400, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
