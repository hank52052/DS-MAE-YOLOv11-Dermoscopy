{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf2ad89-3386-41bf-ae48-638b053e06d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from ultralytics import YOLO\n",
    "import tqdm\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "model = YOLO(\"./yolo_training/962/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9c432b-21b6-4f52-a657-7495775f869f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = \"../../Dataset/isic/HAM10000/cheat/test/\"\n",
    "label_trans = {'AKIEC': 0, 'BCC': 1, 'BKL': 2, 'DF': 3, 'MEL': 4, 'NV': 5, 'VASC': 6}\n",
    "data, label = [], []\n",
    "for types in os.listdir(path):\n",
    "    local_path = path + types + \"/\"\n",
    "    for i in tqdm.tqdm(os.listdir(local_path)):\n",
    "        img_path = local_path + i\n",
    "        img = cv2.imread(img_path)\n",
    "        data.append(img)\n",
    "        label.append(label_trans[types])\n",
    "data, label = np.array(data), np.array(label)\n",
    "label_catagorical = np.eye(7)[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49072c93-a98d-4858-854c-a84e89e82cf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predict_proba, predict_numerical = [], []\n",
    "for i in tqdm.tqdm(data):\n",
    "    pre = model.predict(i, verbose=False)\n",
    "    predict_proba.append(pre[0].probs.data.cpu().numpy())\n",
    "    predict_numerical.append(pre[0].probs.top1)\n",
    "predict_proba = np.array(predict_proba)\n",
    "predict_numerical = np.array(predict_numerical)\n",
    "print(predict_proba.shape, predict_numerical.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1008f1d8-a8a7-468f-a6d9-05e5afc84d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, matthews_corrcoef, jaccard_score, f1_score, precision_score, roc_auc_score\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "\n",
    "class_names = ['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC']\n",
    "\n",
    "columns = [\"Top-1 Accuracy\", \"Balanced Accuracy\", \"MCC\", \"Jaccard Score\", \"F1-score\", \"Precision\", \"OvO AUC\"]\n",
    "index = class_names + [\"Overall\"]\n",
    "results = pd.DataFrame(index=index, columns=columns)\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    true_binary = (label == i).astype(int)\n",
    "    pred_binary = (predict_numerical == i).astype(int)\n",
    "\n",
    "    results.loc[class_name, \"Top-1 Accuracy\"] = accuracy_score(true_binary, pred_binary)\n",
    "    results.loc[class_name, \"Balanced Accuracy\"] = balanced_accuracy_score(true_binary, pred_binary)\n",
    "    results.loc[class_name, \"MCC\"] = matthews_corrcoef(true_binary, pred_binary)\n",
    "    results.loc[class_name, \"Jaccard Score\"] = jaccard_score(true_binary, pred_binary)\n",
    "    results.loc[class_name, \"F1-score\"] = f1_score(true_binary, pred_binary)\n",
    "    results.loc[class_name, \"Precision\"] = precision_score(true_binary, pred_binary)\n",
    "\n",
    "results.loc[\"Overall\", \"Top-1 Accuracy\"] = accuracy_score(label, predict_numerical)\n",
    "results.loc[\"Overall\", \"Balanced Accuracy\"] = balanced_accuracy_score(label, predict_numerical)\n",
    "results.loc[\"Overall\", \"MCC\"] = matthews_corrcoef(label, predict_numerical)\n",
    "results.loc[\"Overall\", \"Jaccard Score\"] = jaccard_score(label, predict_numerical, average='macro')\n",
    "results.loc[\"Overall\", \"F1-score\"] = f1_score(label, predict_numerical, average='weighted')  # 加權\n",
    "results.loc[\"Overall\", \"Precision\"] = precision_score(label, predict_numerical, average='weighted')  # 加權\n",
    "\n",
    "ovo_auc_per_class = {class_name: [] for class_name in class_names}\n",
    "ovo_auc_scores = []\n",
    "\n",
    "for class1, class2 in combinations(range(len(class_names)), 2):\n",
    "    mask = (label == class1) | (label == class2)\n",
    "    \n",
    "    if np.sum(mask) < 2: \n",
    "        continue\n",
    "\n",
    "    y_true_binary = (label[mask] == class1).astype(int)\n",
    "    y_score_binary = predict_proba[mask, class1]\n",
    "\n",
    "    try:\n",
    "        auc_score = roc_auc_score(y_true_binary, y_score_binary)\n",
    "        ovo_auc_scores.append(auc_score)\n",
    "\n",
    "        ovo_auc_per_class[class_names[class1]].append(auc_score)\n",
    "        ovo_auc_per_class[class_names[class2]].append(auc_score)\n",
    "\n",
    "    except ValueError:\n",
    "        continue\n",
    "\n",
    "for class_name in class_names:\n",
    "    if ovo_auc_per_class[class_name]:\n",
    "        results.loc[class_name, \"OvO AUC\"] = np.mean(ovo_auc_per_class[class_name])\n",
    "\n",
    "\n",
    "results.loc[\"Overall\", \"OvO AUC\"] = np.mean(ovo_auc_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e38e20-8d65-441b-a7cd-b975f11bbddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.astype(\"float32\").to_csv(\"./overall_diseace.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85099fa7-9af0-480b-90c6-f4a20835c2a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os, cv2, tqdm, numpy as np, pandas as pd\n",
    "from itertools import combinations\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import (accuracy_score, balanced_accuracy_score, matthews_corrcoef,\n",
    "                             jaccard_score, f1_score, precision_score, roc_auc_score)\n",
    "\n",
    "DATA_DIR = \"../../Dataset/isic/HAM10000/cheat/test/\"\n",
    "CLASS_NAMES = ['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC']\n",
    "LABEL_MAP   = {c:i for i,c in enumerate(CLASS_NAMES)}\n",
    "\n",
    "BLUR_SETTINGS = OrderedDict({\n",
    "    \"original\": None,\n",
    "    \"bilateral_d5\":  {\"d\": 5,  \"sigmaColor\": 25,  \"sigmaSpace\": 25},\n",
    "    \"bilateral_d9\":  {\"d\": 9,  \"sigmaColor\": 75,  \"sigmaSpace\": 75},\n",
    "})\n",
    "\n",
    "def load_dataset(data_dir, label_map):\n",
    "    imgs, labels = [], []\n",
    "    for cls in CLASS_NAMES:\n",
    "        cls_dir = os.path.join(data_dir, cls)\n",
    "        files = sorted(os.listdir(cls_dir))\n",
    "        for fn in tqdm.tqdm(files, desc=f\"Loading {cls:>5}\", leave=False):\n",
    "            img = cv2.imread(os.path.join(cls_dir, fn)) \n",
    "            imgs.append(img)\n",
    "            labels.append(label_map[cls])\n",
    "    return imgs, np.array(labels)\n",
    "\n",
    "def apply_bilateral(img, params):\n",
    "    if params is None:\n",
    "        return img\n",
    "    return cv2.bilateralFilter(img, d=params[\"d\"],\n",
    "                               sigmaColor=params[\"sigmaColor\"],\n",
    "                               sigmaSpace=params[\"sigmaSpace\"])\n",
    "\n",
    "def batch_predict(model, images):\n",
    "    proba_list, top1_list = [], []\n",
    "    for img in tqdm.tqdm(images, desc=\"Inference\", leave=False):\n",
    "        img_in = img\n",
    "        pred = model.predict(img_in, verbose=False)\n",
    "        probs = pred[0].probs.data.cpu().numpy()          # [C]\n",
    "        proba_list.append(probs)\n",
    "        top1_list.append(pred[0].probs.top1)              # int\n",
    "    return np.vstack(proba_list), np.array(top1_list)\n",
    "\n",
    "def metrics_per_condition(labels, y_pred, y_proba):\n",
    "    cols = [\"Top-1 Accuracy\",\"Balanced Accuracy\",\"MCC\",\"Jaccard Score\",\n",
    "            \"F1-score\",\"Precision\",\"OvO AUC\"]\n",
    "    idx  = CLASS_NAMES + [\"Overall\"]\n",
    "    df   = pd.DataFrame(index=idx, columns=cols, dtype=float)\n",
    "\n",
    "    for i, cls in enumerate(CLASS_NAMES):\n",
    "        y_true_bin = (labels == i).astype(int)\n",
    "        y_pred_bin = (y_pred == i).astype(int)\n",
    "        df.loc[cls, \"Top-1 Accuracy\"]   = accuracy_score(y_true_bin, y_pred_bin)\n",
    "        df.loc[cls, \"Balanced Accuracy\"]= balanced_accuracy_score(y_true_bin, y_pred_bin)\n",
    "        df.loc[cls, \"MCC\"]              = matthews_corrcoef(y_true_bin, y_pred_bin)\n",
    "        df.loc[cls, \"Jaccard Score\"]    = jaccard_score(y_true_bin, y_pred_bin, zero_division=0)\n",
    "        df.loc[cls, \"F1-score\"]         = f1_score(y_true_bin, y_pred_bin, zero_division=0)\n",
    "        df.loc[cls, \"Precision\"]        = precision_score(y_true_bin, y_pred_bin, zero_division=0)\n",
    "\n",
    "    df.loc[\"Overall\",\"Top-1 Accuracy\"]    = accuracy_score(labels, y_pred)\n",
    "    df.loc[\"Overall\",\"Balanced Accuracy\"] = balanced_accuracy_score(labels, y_pred)\n",
    "    df.loc[\"Overall\",\"MCC\"]               = matthews_corrcoef(labels, y_pred)\n",
    "    df.loc[\"Overall\",\"Jaccard Score\"]     = jaccard_score(labels, y_pred, average='macro', zero_division=0)\n",
    "    df.loc[\"Overall\",\"F1-score\"]          = f1_score(labels, y_pred, average='weighted', zero_division=0)\n",
    "    df.loc[\"Overall\",\"Precision\"]         = precision_score(labels, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "    ovo_scores = []\n",
    "    per_cls_aucs = {c:[] for c in CLASS_NAMES}\n",
    "    num_classes = len(CLASS_NAMES)\n",
    "    for c1, c2 in combinations(range(num_classes), 2):\n",
    "        mask = (labels == c1) | (labels == c2)\n",
    "        if mask.sum() < 2: \n",
    "            continue\n",
    "        y_true = (labels[mask] == c1).astype(int)\n",
    "        y_scr  = y_proba[mask, c1] \n",
    "        try:\n",
    "            auc = roc_auc_score(y_true, y_scr)\n",
    "            ovo_scores.append(auc)\n",
    "            per_cls_aucs[CLASS_NAMES[c1]].append(auc)\n",
    "            per_cls_aucs[CLASS_NAMES[c2]].append(auc)\n",
    "        except ValueError:\n",
    "            pass\n",
    "    for cls in CLASS_NAMES:\n",
    "        if per_cls_aucs[cls]:\n",
    "            df.loc[cls, \"OvO AUC\"] = float(np.mean(per_cls_aucs[cls]))\n",
    "    if ovo_scores:\n",
    "        df.loc[\"Overall\",\"OvO AUC\"] = float(np.mean(ovo_scores))\n",
    "    return df\n",
    "\n",
    "def evaluate_under_blurs(model, data_dir=DATA_DIR, blur_settings=BLUR_SETTINGS):\n",
    "    images, labels = load_dataset(data_dir, LABEL_MAP) \n",
    "    all_results, summary_rows = {}, []\n",
    "\n",
    "    for name, params in blur_settings.items():\n",
    "        pbar = tqdm.tqdm(total=len(images)*2, desc=f\"[{name}] preparing\", dynamic_ncols=True)\n",
    "        imgs_blur = []\n",
    "        for img in images:\n",
    "            imgs_blur.append(apply_bilateral(img, params))\n",
    "            pbar.update(1)\n",
    "            if pbar.n % 50 == 0:\n",
    "                pbar.set_description(f\"[{name}] blurring\")\n",
    "\n",
    "        proba_list, top1_list = [], []\n",
    "        for img in imgs_blur:\n",
    "            pred = model.predict(img, verbose=False)\n",
    "            probs = pred[0].probs.data.cpu().numpy()\n",
    "            proba_list.append(probs)\n",
    "            top1_list.append(pred[0].probs.top1)\n",
    "            pbar.update(1)\n",
    "            if pbar.n % 50 == 0:\n",
    "                pbar.set_description(f\"[{name}] inference\")\n",
    "        pbar.close()\n",
    "\n",
    "        proba = np.vstack(proba_list)\n",
    "        preds  = np.array(top1_list)\n",
    "        df = metrics_per_condition(labels, preds, proba)\n",
    "        all_results[name] = df\n",
    "        summary_rows.append((name, df.loc[\"Overall\"]))\n",
    "\n",
    "    summary = pd.DataFrame({k: v for k, v in summary_rows}).T\n",
    "    print(\"\\n=== Overall summary across conditions ===\")\n",
    "    print(summary.round(4))\n",
    "    return all_results, summary\n",
    "\n",
    "all_results, summary = evaluate_under_blurs(model)\n",
    "summary.to_csv(\"metrics_summary_blurs.csv\", index=True)\n",
    "all_results[\"original\"].to_csv(\"metrics_perclass_original.csv\")\n",
    "all_results[\"bilateral_d15\"].to_csv(\"metrics_perclass_bilateral_d15.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a79622-0704-4254-8867-d39927bb7f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "class_names = ['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC']\n",
    "\n",
    "print(balanced_accuracy_score(label, predict_numerical))\n",
    "plt.figure(figsize=(10,10))\n",
    "ax = plt.subplot(111)\n",
    "cm = confusion_matrix(label, predict_numerical)\n",
    "ConfusionMatrixDisplay(cm, display_labels=class_names).plot(ax=ax, cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted label\", weight=\"bold\", fontsize=23)\n",
    "plt.ylabel(\"True label\", weight=\"bold\", fontsize=23)\n",
    "plt.xticks(weight=\"bold\")\n",
    "plt.yticks(weight=\"bold\")\n",
    "plt.title(\"Confusion Matrix\", weight=\"bold\", fontsize=25)\n",
    "plt.savefig(\"./confusion.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fa6567-fe1b-44be-bdd9-8547983936ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "sns.set_style(\"white\")\n",
    "class_names = ['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC']\n",
    "\n",
    "y_true = label_catagorical.copy()\n",
    "y_score = predict_proba  \n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = plt.cm.Set2(np.linspace(0, 1, len(class_names)))\n",
    "\n",
    "auc_values = []\n",
    "tpr_values_macro = []\n",
    "tpr_values_micro = []\n",
    "\n",
    "for i, color in zip(range(len(class_names)), colors):\n",
    "    fpr, tpr, _ = roc_curve(y_true[:, i], y_score[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    auc_values.append(roc_auc)\n",
    "    tpr_values_macro.append(np.interp(np.linspace(0, 1, 100), fpr, tpr))  # 統一插值\n",
    "    plt.plot(fpr, tpr, color=color, alpha=0.5, label=f'{class_names[i]} (AUC = {roc_auc:.3f})')\n",
    "\n",
    "fpr_micro, tpr_micro, _ = roc_curve(y_true.ravel(), y_score.ravel())\n",
    "roc_auc_micro = auc(fpr_micro, tpr_micro)\n",
    "\n",
    "tpr_values_micro = np.array([np.interp(np.linspace(0, 1, 100), fpr_micro, tpr_micro)])\n",
    "\n",
    "plt.plot(fpr_micro, tpr_micro, label=f'Micro-Average (AUC = {roc_auc_micro:.3f})', color='blue', linewidth=2)\n",
    "\n",
    "all_fpr = np.linspace(0, 1, 100)\n",
    "mean_tpr_macro = np.mean(tpr_values_macro, axis=0)\n",
    "std_tpr_macro = np.std(tpr_values_macro, axis=0)\n",
    "roc_auc_macro = auc(all_fpr, mean_tpr_macro)\n",
    "\n",
    "plt.plot(all_fpr, mean_tpr_macro, label=f'Macro-Average (AUC = {roc_auc_macro:.3f})', color='red', linewidth=2)\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves with Micro and Macro AUC')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(len(class_names)):\n",
    "    precision, recall, _ = precision_recall_curve(y_true[:, i], y_score[:, i])\n",
    "    ap = average_precision_score(y_true[:, i], y_score[:, i])\n",
    "    plt.plot(recall, precision, label=f\"{class_names[i]} (AP={ap:.3f})\")\n",
    "\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9e4630-07ec-4917-b2ff-bfeb246a9f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "our_model = {\n",
    "    \"Model\": \"YOLOv11s + Full Enhancements\",\n",
    "    \"Accuracy\": 96.10,\n",
    "    \"AUC\": 0.9996,\n",
    "    \"Average Precision\": 0.9625, \n",
    "    \"Extra Training Data\": False,\n",
    "    \"Year\": 2025\n",
    "}\n",
    "\n",
    "other_models = [\n",
    "    {\"Model\": \"FixCaps\", \"Accuracy\": 96.49, \"AUC\": \"-\", \"Average Precision\": \"-\", \"Extra Training Data\": True, \"Year\": 2022},\n",
    "    {\"Model\": \"IRv2+Soft Attention\", \"Accuracy\": 93.4, \"AUC\": 0.984, \"Average Precision\": 0.937, \"Extra Training Data\": True, \"Year\": 2021},\n",
    "    {\"Model\": \"Multi-Resolution Efficient Nets\", \"Accuracy\": 92.6, \"AUC\": \"-\", \"Average Precision\": \"-\", \"Extra Training Data\": True, \"Year\": 2020},\n",
    "    {\"Model\": \"Two-Path CNN\", \"Accuracy\": 88.6, \"AUC\": \"-\", \"Average Precision\": \"-\", \"Extra Training Data\": True, \"Year\": 2020},\n",
    "    {\"Model\": \"ISIC 2019 Analysis\", \"Accuracy\": 85.1, \"AUC\": \"-\", \"Average Precision\": \"-\", \"Extra Training Data\": True, \"Year\": 2020},\n",
    "    {\"Model\": \"Siamese Network\", \"Accuracy\": 83.2, \"AUC\": \"-\", \"Average Precision\": \"-\", \"Extra Training Data\": True, \"Year\": 2020},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame([our_model] + other_models)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=df, x=\"Accuracy\", y=\"Model\", hue=\"Extra Training Data\", palette=\"bwr\", dodge=False)\n",
    "plt.xlabel(\"Accuracy (%)\", weight=\"bold\")\n",
    "plt.ylabel(\"Model\", weight=\"bold\")\n",
    "plt.title(\"Comparison of Skin Lesion Classification Models\", weight=\"bold\")\n",
    "plt.legend(title=\"Extra Data\", loc=\"lower right\")\n",
    "plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.7)\n",
    "plt.savefig(\"./comparation.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
