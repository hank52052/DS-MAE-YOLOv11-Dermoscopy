{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f1bcc7-fac0-4ab7-858c-affc225efbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img_path = \"../../Dataset/isic/HAM10000/images/ISIC_0024748.jpg\"\n",
    "\n",
    "img = cv2.imread(img_path)[:, :, ::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8990ccd-8e09-4574-a8f1-9022c9a77b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4905dfe8-eb31-46a2-ba6c-78bb4844e494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_diagonal_cross_kernel(size=13):\n",
    "    kernel = np.zeros((size, size), dtype=np.uint8)\n",
    "    center = size // 2\n",
    "\n",
    "    for i in range(0, size, 2):\n",
    "        kernel[center, i] = 1\n",
    "        kernel[i, center] = 1\n",
    "\n",
    "    for i in range(0, size, 2):\n",
    "        kernel[i, i] = 1\n",
    "        kernel[i, size - 1 - i] = 1\n",
    "    \n",
    "    kernel[center, center - 1:center + 2] = 0\n",
    "    kernel[center - 1:center + 2, center] = 0\n",
    "    kernel[center - 1, center - 1] = 0\n",
    "    kernel[center - 1, center + 1] = 0\n",
    "    kernel[center + 1, center - 1] = 0\n",
    "    kernel[center + 1, center + 1] = 0\n",
    "\n",
    "    return kernel\n",
    "\n",
    "kernel_struct = generate_diagonal_cross_kernel(13)\n",
    "\n",
    "plt.imshow(kernel_struct, cmap=\"gray\")\n",
    "plt.title(\"Generated 13√ó13 Diagonal Cross Kernel with Gaps\")\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(\"./kernel.png\", dpi=400, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(kernel_struct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191520b6-dea4-46a8-9b17-731afc5fb37d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "skin_image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "kernel_struct = generate_diagonal_cross_kernel(27)\n",
    "\n",
    "top_hat = cv2.morphologyEx(skin_image, cv2.MORPH_BLACKHAT, kernel_struct)\n",
    "_, binary_mask = cv2.threshold(top_hat, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "kernel_open = cv2.getStructuringElement(cv2.MORPH_CROSS, (9,9))\n",
    "binary_mask_cleaned = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel_open)\n",
    "img = cv2.imread(img_path)\n",
    "image_inpainted = cv2.inpaint(img, binary_mask_cleaned, inpaintRadius=5, flags=cv2.INPAINT_TELEA)\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 6))\n",
    "titles = [\"Original Image\", \"Black-hat (Extracted Hair)\", \"Otsu Binary Mask\", \"Inpainted\"]\n",
    "images = [img, top_hat, binary_mask_cleaned, image_inpainted]\n",
    "\n",
    "for ax, img, title in zip(axes, images, titles):\n",
    "    if len(img.shape) == 2:\n",
    "        ax.imshow(img, cmap=\"gray\")\n",
    "    else:\n",
    "        ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    ax.set_title(title)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./aug_show_flow.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0522cb7c-0435-405d-a4a1-50d93f165ab5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "folder = [\"train\", \"test\", \"val\"]\n",
    "types = ['MEL', 'AKIEC', 'BCC', 'NV', 'BKL', 'VASC', 'DF']\n",
    "\n",
    "for i in folder:\n",
    "    for j in types:\n",
    "        for k in tqdm(os.listdir(\"/home/hank52052/Dataset/isic/HAM10000/yolo_format_process/{}/{}/\".format(i,j))):\n",
    "            img_path = \"/home/hank52052/Dataset/isic/HAM10000/yolo_format_process/{}/{}/\".format(i,j) + k\n",
    "        \n",
    "            skin_image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            kernel_struct = generate_diagonal_cross_kernel(27)\n",
    "            \n",
    "            top_hat = cv2.morphologyEx(skin_image, cv2.MORPH_BLACKHAT, kernel_struct)\n",
    "            _, binary_mask = cv2.threshold(top_hat, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "            \n",
    "            kernel_open = cv2.getStructuringElement(cv2.MORPH_CROSS, (9,9))\n",
    "            binary_mask_cleaned = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel_open)\n",
    "            \n",
    "            img = cv2.imread(img_path)[:, :, ::-1]\n",
    "            image_inpainted = cv2.inpaint(img, binary_mask_cleaned, inpaintRadius=5, flags=cv2.INPAINT_TELEA)\n",
    "            plt.imsave(img_path, image_inpainted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8470e0-cc3f-4002-acba-bd88510edbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(121)\n",
    "plt.imshow(img)\n",
    "plt.subplot(122)\n",
    "plt.imshow(image_inpainted)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d691b62-2cce-412b-a2b3-b95c6a9bcd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "base_dir = \"/home/hank52052/Dataset/isic/HAM10000/cheat_four\"\n",
    "\n",
    "categories = {\n",
    "    \"MEL\": \"MEL\",\n",
    "    \"BCC\": \"BCC\",\n",
    "    \"AKIEC\": \"SCC\",\n",
    "    \"BKL\": \"Benign\",\n",
    "    \"DF\": \"Benign\",\n",
    "    \"NV\": \"Benign\",\n",
    "    \"VASC\": \"Benign\",\n",
    "}\n",
    "\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    split_path = os.path.join(base_dir, split)\n",
    "    for old_cat in os.listdir(split_path):\n",
    "        old_cat_path = os.path.join(split_path, old_cat)\n",
    "        if os.path.isdir(old_cat_path):\n",
    "            new_cat = categories.get(old_cat, \"Benign\")\n",
    "            new_cat_path = os.path.join(split_path, new_cat)\n",
    "            if new_cat != old_cat:\n",
    "                os.makedirs(new_cat_path, exist_ok=True)\n",
    "                for file in os.listdir(old_cat_path):\n",
    "                    old_file_path = os.path.join(old_cat_path, file)\n",
    "                    new_file_path = os.path.join(new_cat_path, file)\n",
    "                    shutil.move(old_file_path, new_file_path)\n",
    "                os.rmdir(old_cat_path)\n",
    "\n",
    "print(\"Ë≥áÊñôÂàÜÈ°ûÂÆåÊàêÔºåÂéüÁõÆÈåÑÂ∑≤Êõ¥Êñ∞„ÄÇ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7bbe39-03c5-4036-a981-4ed2c3967d96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install thop fvcore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e546a4-8fc2-4f2f-acd0-ef1e47b238d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58118d5-dd45-4998-b59c-f4c07439d30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"./yolo_training/962/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26903834-919b-4181-b7bc-d0de8698a1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(p.numel() for p in model.model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4d4575-e9c0-46b8-ab6c-cf1e5ed90aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83c8936-abf6-4231-828d-b80366c0d120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cv2.imread(\"../../Dataset/isic/HAM10000/cheat_four/train/BCC/ISIC_0024345.jpg\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec145f77-cd58-4098-9550-4ccf983f6b20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fvcore.nn import FlopCountAnalysis\n",
    "import torch\n",
    "\n",
    "model_c = model.model.eval()\n",
    "dummy = torch.randn(1, 3, 450, 600)\n",
    "\n",
    "flops = FlopCountAnalysis(model_c, dummy)\n",
    "print(f\"Total FLOPs: {flops.total() / 1e9:.3f} GFLOPs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76af268-bcfa-46c5-a978-8a1da1aba6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "model_c = model.model.eval().cuda()\n",
    "\n",
    "dummy = torch.randn(1, 3, 450, 600).cuda()\n",
    "\n",
    "for _ in range(10):\n",
    "    _ = model_c(dummy)\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "start = time.time()\n",
    "\n",
    "N = 100 \n",
    "for _ in range(N):\n",
    "    _ = model_c(dummy)\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "end = time.time()\n",
    "\n",
    "avg_ms = (end - start) / N * 1000\n",
    "fps = 1000 / avg_ms\n",
    "\n",
    "print(f\"Inference Time: {avg_ms:.3f} ms\")\n",
    "print(f\"FPS: {fps:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcb28a2-1378-46e9-8355-79a2970eed5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "model_c = model.model.eval().cpu()    \n",
    "\n",
    "\n",
    "dummy = torch.randn(1, 3, 450, 600).cpu()\n",
    "\n",
    "for _ in range(3):\n",
    "    _ = model_c(dummy)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "N = 20   \n",
    "for _ in range(N):\n",
    "    _ = model_c(dummy)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "avg_ms = (end - start) / N * 1000\n",
    "fps = 1000 / avg_ms\n",
    "\n",
    "print(f\"[CPU] Inference Time: {avg_ms:.2f} ms\")\n",
    "print(f\"[CPU] FPS: {fps:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342b0254-07b2-40ab-a97d-083f5940b53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
    "import tensorflow as tf\n",
    "import keras_cv_attention_models as cv\n",
    "tf.test.is_gpu_available()\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "import sys\n",
    "from keras_flops.flops_counter import get_flops\n",
    "\n",
    "def isic_model(shape=(450, 600, 3)):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(cv.mobilevit.MobileViT_V2_050(num_classes=0, input_shape=(450, 600, 3)))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(256))\n",
    "    model.add(tf.keras.layers.Dropout(0.2))\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dense(128))\n",
    "    model.add(tf.keras.layers.Dropout(0.2))\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dense(4))\n",
    "    model.add(tf.keras.layers.Softmax())\n",
    "    return model\n",
    "\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303fdb24-9ae2-45a2-be37-1fe2504a6a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "model = isic_model()\n",
    "\n",
    "input_shape = (1, 450, 600, 3)\n",
    "dummy = np.random.random(input_shape).astype(np.float32)\n",
    "\n",
    "\n",
    "total_params = model.count_params()\n",
    "print(f\"Total Params: {total_params/1e6:.3f} M\")\n",
    "\n",
    "def get_flops_tf2(model, input_shape=(1, 450, 600, 3)):\n",
    "    print(\"--- Starting FLOPs calculation (TF 2.x method) ---\")\n",
    "    \n",
    "   \n",
    "    concrete_func = tf.function(model).get_concrete_function(\n",
    "        tf.TensorSpec(input_shape, tf.float32)\n",
    "    )\n",
    "\n",
    "    frozen_output = convert_variables_to_constants_v2(\n",
    "        concrete_func,\n",
    "        lower_control_flow=False\n",
    "    )\n",
    "    \n",
    "    if isinstance(frozen_output, (list, tuple)) and len(frozen_output) == 2:\n",
    "        graph_def = frozen_output[1]\n",
    "    elif hasattr(frozen_output, 'graph') and hasattr(frozen_output.graph, 'as_graph_def'):\n",
    "        graph_def = frozen_output.graph.as_graph_def()\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected return type from convert_variables_to_constants_v2: {type(frozen_output)}\")\n",
    "\n",
    "\n",
    "    flops = tf.compat.v1.profiler.profile(\n",
    "        graph=graph_def,\n",
    "        options=tf.compat.v1.profiler.ProfileOptionBuilder.float_operation(),\n",
    "    )\n",
    "    \n",
    "    return flops.total_float_ops\n",
    "try:\n",
    "    flops = get_flops_tf2(model, input_shape=(1,450,600,3))\n",
    "    print(f\"Total FLOPs: {flops/1e9:.3f} GFLOPs\")\n",
    "except Exception as e:\n",
    "    print(\"FLOPs calculation failed, reason:\", e)\n",
    "\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def inference_step(x):\n",
    "    return model(x, training=False)\n",
    "\n",
    "def measure_inference(device, dummy, runs=50):\n",
    "    with tf.device(device):\n",
    "        # warm-up\n",
    "        for _ in range(10):\n",
    "            _ = inference_step(dummy)\n",
    "\n",
    "        start = time.time()\n",
    "        for _ in range(runs):\n",
    "            _ = inference_step(dummy)\n",
    "        end = time.time()\n",
    "\n",
    "        avg_ms = (end - start) / runs * 1000\n",
    "        fps = 1000 / avg_ms\n",
    "    return avg_ms, fps\n",
    "\n",
    "\n",
    "try:\n",
    "    gpu_time, gpu_fps = measure_inference(\"/GPU:0\", dummy)\n",
    "    print(f\"[GPU] Inference Time: {gpu_time:.3f} ms   | FPS: {gpu_fps:.2f}\")\n",
    "except:\n",
    "    print(\"[GPU] No GPU available\")\n",
    "\n",
    "\n",
    "cpu_time, cpu_fps = measure_inference(\"/CPU:0\", dummy, runs=20)\n",
    "print(f\"[CPU] Inference Time: {cpu_time:.3f} ms   | FPS: {cpu_fps:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfd5205-ba68-40cc-baf3-be362adc5e61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
    "import tensorflow as tf\n",
    "import keras_cv_attention_models as cv \n",
    "import time\n",
    "\n",
    "try:\n",
    "    from keras_flops import get_flops\n",
    "except ImportError:\n",
    "    try:\n",
    "        from keras_flops.flops_counter import get_flops\n",
    "    except ImportError:\n",
    "        print(\"Error: The 'keras_flops' package is not installed or the import path is incorrect.\")\n",
    "        get_flops = None\n",
    "\n",
    "\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
    "\n",
    "def isic_model(shape=(450, 600, 3)):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(cv.tinyvit.TinyViT_5M(num_classes=0, input_shape=shape, pretrained=None))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(256))\n",
    "    model.add(tf.keras.layers.Dropout(0.2))\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dense(128))\n",
    "    model.add(tf.keras.layers.Dropout(0.2))\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dense(4))\n",
    "    model.add(tf.keras.layers.Softmax())\n",
    "    return model\n",
    "\n",
    "INPUT_SIZE = (450, 600, 3)\n",
    "input_shape = (1,) + INPUT_SIZE\n",
    "model = isic_model(shape=INPUT_SIZE) \n",
    "dummy = np.random.random(input_shape).astype(np.float32)\n",
    "\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def inference_step(x):\n",
    "    return model(x, training=False)\n",
    "\n",
    "def measure_inference(device, dummy, runs=50):\n",
    "    \"\"\"Ê∏¨ÈáèÊåáÂÆöË®≠ÂÇô‰∏äÁöÑÂπ≥ÂùáÊé®ÁêÜÊôÇÈñìÂíå FPS\"\"\"\n",
    "    with tf.device(device):\n",
    "        for _ in range(10):\n",
    "            _ = inference_step(dummy)\n",
    "\n",
    "        start = time.time()\n",
    "        for _ in range(runs):\n",
    "            _ = inference_step(dummy)\n",
    "        end = time.time()\n",
    "\n",
    "        avg_ms = (end - start) / runs * 1000\n",
    "        fps = 1000 / avg_ms\n",
    "    return avg_ms, fps\n",
    "\n",
    "\n",
    "total_params = model.count_params()\n",
    "params_m = total_params / 1e6\n",
    "\n",
    "flops_g = float('nan')\n",
    "if get_flops:\n",
    "    try:\n",
    "        print(\"\\n--- Running FLOPs calculation (keras-flops) ---\")\n",
    "        \n",
    "        import contextlib\n",
    "        import sys\n",
    "        \n",
    "        with contextlib.redirect_stdout(None):\n",
    "             total_flops = get_flops(model, batch_size=input_shape[0])\n",
    "        \n",
    "        flops_g = total_flops / 1e9\n",
    "        print(f\"FLOPs calculation completed. Result: {flops_g:.3f} GFLOPs\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"FLOPs calculation failed (keras-flops), reason: {e}\")\n",
    "\n",
    "gpu_time, gpu_fps, cpu_time, cpu_fps = float('nan'), float('nan'), float('nan'), float('nan')\n",
    "\n",
    "try:\n",
    "    if tf.config.list_physical_devices('GPU'):\n",
    "        gpu_time, gpu_fps = measure_inference(\"/GPU:0\", dummy, runs=50)\n",
    "except Exception as e:\n",
    "    if str(e) != \"Cannot find any device in the device list.\":\n",
    "        print(f\"[GPU] Test failed unexpectedly: {e}\")\n",
    "\n",
    "cpu_time, cpu_fps = measure_inference(\"/CPU:0\", dummy, runs=20) \n",
    "\n",
    "\n",
    "data = {\n",
    "    'Model': ['MobileViT_V2_050 + Classifier'],\n",
    "    'Params (M)': [params_m],\n",
    "    'FLOPs (G)': [flops_g],\n",
    "    'GPU Time (ms)': [gpu_time],\n",
    "    'GPU FPS': [gpu_fps],\n",
    "    'CPU Time (ms)': [cpu_time],\n",
    "    'CPU FPS': [cpu_fps]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df_styled = df.style.format({\n",
    "    'Params (M)': '{:.3f}',\n",
    "    'FLOPs (G)': '{:.3f}',\n",
    "    'GPU Time (ms)': '{:.3f}',\n",
    "    'GPU FPS': '{:.2f}',\n",
    "    'CPU Time (ms)': '{:.3f}',\n",
    "    'CPU FPS': '{:.2f}',\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"             üöÄ Ê®°ÂûãÊÄßËÉΩÁ∂úÂêàÂ†±Âëä (Model Performance Summary) üöÄ\")\n",
    "print(\"=\"*80)\n",
    "print(df.to_markdown(index=False, floatfmt=\".3f\"))\n",
    "print(\"=\"*80 + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
