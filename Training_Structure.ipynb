{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b07df58-329f-4392-8ceb-130afe0d0b06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading YOLOv11 architecture from yolo11s.pt...\n",
      "Backbone Output Shape: torch.Size([1, 512, 7, 7]) (Channels: 512)\n",
      "è³‡æ–™ä¾†æº: /home/hank52052/Dataset/isic/HAM10000/yolo_format/train\n",
      "å…±æ‰¾åˆ° 46935 å¼µåœ–ç‰‡\n",
      "é–‹å§‹ DS-MAE é è¨“ç·´...\n",
      "Epoch [1/3] Step 0 Loss: 0.0719\n",
      "Epoch [1/3] Step 50 Loss: 0.0469\n",
      "Epoch [1/3] Step 100 Loss: 0.0492\n",
      "Epoch [1/3] Step 150 Loss: 0.0579\n",
      "Epoch [1/3] Step 200 Loss: 0.0408\n",
      "Epoch [1/3] Step 250 Loss: 0.0340\n",
      "Epoch [1/3] Step 300 Loss: 0.0230\n",
      "Epoch [1/3] Step 350 Loss: 0.0199\n",
      "Epoch [1/3] Step 400 Loss: 0.0305\n",
      "Epoch [1/3] Step 450 Loss: 0.0196\n",
      "Epoch [1/3] Step 500 Loss: 0.0266\n",
      "Epoch [1/3] Step 550 Loss: 0.0233\n",
      "Epoch [1/3] Step 600 Loss: 0.0227\n",
      "Epoch [1/3] Step 650 Loss: 0.0200\n",
      "Epoch [1/3] Step 700 Loss: 0.0129\n",
      "Epoch [1/3] Step 750 Loss: 0.0143\n",
      "Epoch [1/3] Step 800 Loss: 0.0135\n",
      "Epoch [1/3] Step 850 Loss: 0.0129\n",
      "Epoch [1/3] Step 900 Loss: 0.0163\n",
      "Epoch [1/3] Step 950 Loss: 0.0196\n",
      "Epoch [1/3] Step 1000 Loss: 0.0207\n",
      "Epoch [1/3] Step 1050 Loss: 0.0135\n",
      "Epoch [1/3] Step 1100 Loss: 0.0133\n",
      "Epoch [1/3] Step 1150 Loss: 0.0182\n",
      "Epoch [1/3] Step 1200 Loss: 0.0121\n",
      "Epoch [1/3] Step 1250 Loss: 0.0130\n",
      "Epoch [1/3] Step 1300 Loss: 0.0183\n",
      "Epoch [1/3] Step 1350 Loss: 0.0109\n",
      "Epoch [1/3] Step 1400 Loss: 0.0096\n",
      "Epoch [1/3] Step 1450 Loss: 0.0149\n",
      "Epoch [1/3] Step 1500 Loss: 0.0112\n",
      "Epoch [1/3] Step 1550 Loss: 0.0088\n",
      "Epoch [1/3] Step 1600 Loss: 0.0117\n",
      "Epoch [1/3] Step 1650 Loss: 0.0103\n",
      "Epoch [1/3] Step 1700 Loss: 0.0124\n",
      "Epoch [1/3] Step 1750 Loss: 0.0097\n",
      "Epoch [1/3] Step 1800 Loss: 0.0129\n",
      "Epoch [1/3] Step 1850 Loss: 0.0128\n",
      "Epoch [1/3] Step 1900 Loss: 0.0103\n",
      "Epoch [1/3] Step 1950 Loss: 0.0112\n",
      "Epoch [1/3] Step 2000 Loss: 0.0097\n",
      "Epoch [1/3] Step 2050 Loss: 0.0136\n",
      "Epoch [1/3] Step 2100 Loss: 0.0093\n",
      "Epoch [1/3] Step 2150 Loss: 0.0130\n",
      "Epoch [1/3] Step 2200 Loss: 0.0105\n",
      "Epoch [1/3] Step 2250 Loss: 0.0078\n",
      "Epoch [1/3] Step 2300 Loss: 0.0087\n",
      "Epoch [1/3] Step 2350 Loss: 0.0104\n",
      "Epoch [1/3] Step 2400 Loss: 0.0081\n",
      "Epoch [1/3] Step 2450 Loss: 0.0085\n",
      "Epoch [1/3] Step 2500 Loss: 0.0122\n",
      "Epoch [1/3] Step 2550 Loss: 0.0088\n",
      "Epoch [1/3] Step 2600 Loss: 0.0082\n",
      "Epoch [1/3] Step 2650 Loss: 0.0117\n",
      "Epoch [1/3] Step 2700 Loss: 0.0088\n",
      "Epoch [1/3] Step 2750 Loss: 0.0131\n",
      "Epoch [1/3] Step 2800 Loss: 0.0078\n",
      "Epoch [1/3] Step 2850 Loss: 0.0087\n",
      "Epoch [1/3] Step 2900 Loss: 0.0102\n",
      "Epoch [1/3] Avg Loss: 0.0164\n",
      "Epoch [2/3] Step 0 Loss: 0.0086\n",
      "Epoch [2/3] Step 50 Loss: 0.0077\n",
      "Epoch [2/3] Step 100 Loss: 0.0081\n",
      "Epoch [2/3] Step 150 Loss: 0.0083\n",
      "Epoch [2/3] Step 200 Loss: 0.0079\n",
      "Epoch [2/3] Step 250 Loss: 0.0094\n",
      "Epoch [2/3] Step 300 Loss: 0.0078\n",
      "Epoch [2/3] Step 350 Loss: 0.0112\n",
      "Epoch [2/3] Step 400 Loss: 0.0087\n",
      "Epoch [2/3] Step 450 Loss: 0.0063\n",
      "Epoch [2/3] Step 500 Loss: 0.0087\n",
      "Epoch [2/3] Step 550 Loss: 0.0137\n",
      "Epoch [2/3] Step 600 Loss: 0.0088\n",
      "Epoch [2/3] Step 650 Loss: 0.0087\n",
      "Epoch [2/3] Step 700 Loss: 0.0058\n",
      "Epoch [2/3] Step 750 Loss: 0.0083\n",
      "Epoch [2/3] Step 800 Loss: 0.0088\n",
      "Epoch [2/3] Step 850 Loss: 0.0119\n",
      "Epoch [2/3] Step 900 Loss: 0.0109\n",
      "Epoch [2/3] Step 950 Loss: 0.0102\n",
      "Epoch [2/3] Step 1000 Loss: 0.0087\n",
      "Epoch [2/3] Step 1050 Loss: 0.0099\n",
      "Epoch [2/3] Step 1100 Loss: 0.0076\n",
      "Epoch [2/3] Step 1150 Loss: 0.0099\n",
      "Epoch [2/3] Step 1200 Loss: 0.0089\n",
      "Epoch [2/3] Step 1250 Loss: 0.0070\n",
      "Epoch [2/3] Step 1300 Loss: 0.0063\n",
      "Epoch [2/3] Step 1350 Loss: 0.0091\n",
      "Epoch [2/3] Step 1400 Loss: 0.0075\n",
      "Epoch [2/3] Step 1450 Loss: 0.0067\n",
      "Epoch [2/3] Step 1500 Loss: 0.0081\n",
      "Epoch [2/3] Step 1550 Loss: 0.0078\n",
      "Epoch [2/3] Step 1600 Loss: 0.0098\n",
      "Epoch [2/3] Step 1650 Loss: 0.0107\n",
      "Epoch [2/3] Step 1700 Loss: 0.0082\n",
      "Epoch [2/3] Step 1750 Loss: 0.0089\n",
      "Epoch [2/3] Step 1800 Loss: 0.0082\n",
      "Epoch [2/3] Step 1850 Loss: 0.0083\n",
      "Epoch [2/3] Step 1900 Loss: 0.0063\n",
      "Epoch [2/3] Step 1950 Loss: 0.0084\n",
      "Epoch [2/3] Step 2000 Loss: 0.0095\n",
      "Epoch [2/3] Step 2050 Loss: 0.0053\n",
      "Epoch [2/3] Step 2100 Loss: 0.0071\n",
      "Epoch [2/3] Step 2150 Loss: 0.0062\n",
      "Epoch [2/3] Step 2200 Loss: 0.0085\n",
      "Epoch [2/3] Step 2250 Loss: 0.0059\n",
      "Epoch [2/3] Step 2300 Loss: 0.0074\n",
      "Epoch [2/3] Step 2350 Loss: 0.0089\n",
      "Epoch [2/3] Step 2400 Loss: 0.0072\n",
      "Epoch [2/3] Step 2450 Loss: 0.0082\n",
      "Epoch [2/3] Step 2500 Loss: 0.0058\n",
      "Epoch [2/3] Step 2550 Loss: 0.0056\n",
      "Epoch [2/3] Step 2600 Loss: 0.0097\n",
      "Epoch [2/3] Step 2650 Loss: 0.0056\n",
      "Epoch [2/3] Step 2700 Loss: 0.0069\n",
      "Epoch [2/3] Step 2750 Loss: 0.0060\n",
      "Epoch [2/3] Step 2800 Loss: 0.0062\n",
      "Epoch [2/3] Step 2850 Loss: 0.0095\n",
      "Epoch [2/3] Step 2900 Loss: 0.0062\n",
      "Epoch [2/3] Avg Loss: 0.0081\n",
      "Epoch [3/3] Step 0 Loss: 0.0065\n",
      "Epoch [3/3] Step 50 Loss: 0.0078\n",
      "Epoch [3/3] Step 100 Loss: 0.0084\n",
      "Epoch [3/3] Step 150 Loss: 0.0045\n",
      "Epoch [3/3] Step 200 Loss: 0.0079\n",
      "Epoch [3/3] Step 250 Loss: 0.0055\n",
      "Epoch [3/3] Step 300 Loss: 0.0044\n",
      "Epoch [3/3] Step 350 Loss: 0.0048\n",
      "Epoch [3/3] Step 400 Loss: 0.0053\n",
      "Epoch [3/3] Step 450 Loss: 0.0047\n",
      "Epoch [3/3] Step 500 Loss: 0.0042\n",
      "Epoch [3/3] Step 550 Loss: 0.0042\n",
      "Epoch [3/3] Step 600 Loss: 0.0051\n",
      "Epoch [3/3] Step 650 Loss: 0.0062\n",
      "Epoch [3/3] Step 700 Loss: 0.0063\n",
      "Epoch [3/3] Step 750 Loss: 0.0058\n",
      "Epoch [3/3] Step 800 Loss: 0.0100\n",
      "Epoch [3/3] Step 850 Loss: 0.0074\n",
      "Epoch [3/3] Step 900 Loss: 0.0061\n",
      "Epoch [3/3] Step 950 Loss: 0.0054\n",
      "Epoch [3/3] Step 1000 Loss: 0.0122\n",
      "Epoch [3/3] Step 1050 Loss: 0.0052\n",
      "Epoch [3/3] Step 1100 Loss: 0.0042\n",
      "Epoch [3/3] Step 1150 Loss: 0.0045\n",
      "Epoch [3/3] Step 1200 Loss: 0.0054\n",
      "Epoch [3/3] Step 1250 Loss: 0.0053\n",
      "Epoch [3/3] Step 1300 Loss: 0.0046\n",
      "Epoch [3/3] Step 1350 Loss: 0.0055\n",
      "Epoch [3/3] Step 1400 Loss: 0.0066\n",
      "Epoch [3/3] Step 1450 Loss: 0.0063\n",
      "Epoch [3/3] Step 1500 Loss: 0.0092\n",
      "Epoch [3/3] Step 1550 Loss: 0.0060\n",
      "Epoch [3/3] Step 1600 Loss: 0.0033\n",
      "Epoch [3/3] Step 1650 Loss: 0.0051\n",
      "Epoch [3/3] Step 1700 Loss: 0.0056\n",
      "Epoch [3/3] Step 1750 Loss: 0.0051\n",
      "Epoch [3/3] Step 1800 Loss: 0.0050\n",
      "Epoch [3/3] Step 1850 Loss: 0.0047\n",
      "Epoch [3/3] Step 1900 Loss: 0.0052\n",
      "Epoch [3/3] Step 1950 Loss: 0.0065\n",
      "Epoch [3/3] Step 2000 Loss: 0.0037\n",
      "Epoch [3/3] Step 2050 Loss: 0.0057\n",
      "Epoch [3/3] Step 2100 Loss: 0.0049\n",
      "Epoch [3/3] Step 2150 Loss: 0.0046\n",
      "Epoch [3/3] Step 2200 Loss: 0.0048\n",
      "Epoch [3/3] Step 2250 Loss: 0.0049\n",
      "Epoch [3/3] Step 2300 Loss: 0.0058\n",
      "Epoch [3/3] Step 2350 Loss: 0.0049\n",
      "Epoch [3/3] Step 2400 Loss: 0.0062\n",
      "Epoch [3/3] Step 2450 Loss: 0.0050\n",
      "Epoch [3/3] Step 2500 Loss: 0.0095\n",
      "Epoch [3/3] Step 2550 Loss: 0.0040\n",
      "Epoch [3/3] Step 2600 Loss: 0.0056\n",
      "Epoch [3/3] Step 2650 Loss: 0.0031\n",
      "Epoch [3/3] Step 2700 Loss: 0.0036\n",
      "Epoch [3/3] Step 2750 Loss: 0.0074\n",
      "Epoch [3/3] Step 2800 Loss: 0.0048\n",
      "Epoch [3/3] Step 2850 Loss: 0.0040\n",
      "Epoch [3/3] Step 2900 Loss: 0.0047\n",
      "Epoch [3/3] Avg Loss: 0.0059\n",
      "è¨“ç·´å®Œæˆï¼æ¬Šé‡å·²å„²å­˜ç‚º ds_mae_backbone_weights.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def segment_lesion_auto(image_rgb, min_lesion_frac=0.005):\n",
    "    gray = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    gray = clahe.apply(gray)\n",
    "    inv = 255 - gray\n",
    "    _, th = cv2.threshold(inv, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    th = cv2.medianBlur(th, 5)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))\n",
    "    th = cv2.morphologyEx(th, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "    th = cv2.morphologyEx(th, cv2.MORPH_OPEN,  kernel, iterations=1)\n",
    "    num, labels = cv2.connectedComponents(th)\n",
    "    \n",
    "    if num > 1:\n",
    "        areas = [np.sum(labels == i) for i in range(1, num)]\n",
    "        max_lbl = 1 + int(np.argmax(areas))\n",
    "        mask = (labels == max_lbl)\n",
    "    else:\n",
    "        mask = th.astype(bool)\n",
    "        \n",
    "    if mask.mean() < min_lesion_frac:\n",
    "        mask[:] = False\n",
    "    return mask\n",
    "\n",
    "def mask_by_region_auto(image_rgb, lesion_ratio=0.6, bg_ratio=0.4, mask_value=0, seed=None):\n",
    "    assert image_rgb.ndim == 3 and image_rgb.shape[2] == 3\n",
    "    H, W, _ = image_rgb.shape\n",
    "    lesion_mask = segment_lesion_auto(image_rgb)\n",
    "    \n",
    "    lesion_idx = np.flatnonzero(lesion_mask.ravel())\n",
    "    bg_idx = np.flatnonzero(~lesion_mask.ravel())\n",
    "    \n",
    "    rng = np.random.default_rng(seed)\n",
    "    n_lesion = int(min(len(lesion_idx), max(0, round(lesion_ratio * len(lesion_idx)))))\n",
    "    n_bg     = int(min(len(bg_idx),     max(0, round(bg_ratio     * len(bg_idx)))))\n",
    "    \n",
    "    pick_lesion = rng.choice(lesion_idx, size=n_lesion, replace=False) if n_lesion > 0 else np.array([], dtype=int)\n",
    "    pick_bg     = rng.choice(bg_idx,     size=n_bg,     replace=False) if n_bg > 0     else np.array([], dtype=int)\n",
    "    pick_all    = np.concatenate([pick_lesion, pick_bg])\n",
    "    \n",
    "    masked_img = image_rgb.copy()\n",
    "    if isinstance(mask_value, (tuple, list)) and len(mask_value) == 3:\n",
    "        masked_img.reshape(-1, 3)[pick_all] = mask_value\n",
    "    else:\n",
    "        masked_img.reshape(-1, 3)[pick_all] = (mask_value, mask_value, mask_value)\n",
    "    return masked_img\n",
    "\n",
    "class DSMAEDataset(Dataset):\n",
    "    def __init__(self, img_dir, img_size=224):\n",
    "        self.img_size = img_size\n",
    "        self.img_paths = []\n",
    "        exts = {'jpg', 'jpeg', 'png', 'bmp'}\n",
    "        \n",
    "        for root, _, files in os.walk(img_dir):\n",
    "            for file in files:\n",
    "                if file.split('.')[-1].lower() in exts:\n",
    "                    self.img_paths.append(os.path.join(root, file))\n",
    "        \n",
    "        if len(self.img_paths) == 0:\n",
    "            raise ValueError(f\"No images found in {img_dir}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_paths[idx]\n",
    "        bgr = cv2.imread(img_path)\n",
    "        \n",
    "        if bgr is None:\n",
    "            return torch.zeros(3, self.img_size, self.img_size), torch.zeros(3, self.img_size, self.img_size)\n",
    "            \n",
    "        rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "        rgb = cv2.resize(rgb, (self.img_size, self.img_size))\n",
    "        \n",
    "        masked_img_np = mask_by_region_auto(rgb, lesion_ratio=0.8, bg_ratio=0.1, mask_value=0)\n",
    "        \n",
    "        original_tensor = torch.from_numpy(rgb).permute(2, 0, 1).float() / 255.0\n",
    "        masked_tensor = torch.from_numpy(masked_img_np).permute(2, 0, 1).float() / 255.0\n",
    "        \n",
    "        return masked_tensor, original_tensor\n",
    "\n",
    "class DS_MAE(nn.Module):\n",
    "    def __init__(self, yolo_model_path='yolo11s.pt'):\n",
    "        super(DS_MAE, self).__init__()\n",
    "        full_yolo = YOLO(yolo_model_path)\n",
    "        \n",
    "        # Extract backbone layers (0-9)\n",
    "        original_layers = list(full_yolo.model.model.children())\n",
    "        self.encoder = nn.Sequential(*original_layers[:10])\n",
    "        \n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, 3, 224, 224)\n",
    "            enc_out = self.encoder(dummy)\n",
    "            self.enc_channels = enc_out.shape[1] \n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(self.enc_channels, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256), nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128), nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64), nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32), nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(32, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32), nn.ReLU(True),\n",
    "            nn.Conv2d(32, 3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        return self.decoder(features)\n",
    "    \n",
    "    def get_backbone(self):\n",
    "        return self.encoder\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    BATCH_SIZE = 16\n",
    "    NUM_EPOCHS = 3\n",
    "    IMAGE_DIR = \"/home/hank52052/Dataset/isic/HAM10000/yolo_format/train\"\n",
    "\n",
    "    model = DS_MAE(\"yolo11s.pt\").to(device)\n",
    "    \n",
    "    if os.path.exists(IMAGE_DIR):\n",
    "        dataset = DSMAEDataset(IMAGE_DIR)\n",
    "        \n",
    "        if len(dataset) > 0:\n",
    "            dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "            criterion = nn.MSELoss()\n",
    "            optimizer = optim.Adadelta(model.parameters(), lr=1.0)\n",
    "            scheduler = optim.lr_scheduler.CyclicLR(\n",
    "                optimizer, \n",
    "                base_lr=1e-5, \n",
    "                max_lr=1e-1, \n",
    "                step_size_up=200, \n",
    "                mode='triangular',\n",
    "                cycle_momentum=False\n",
    "            )\n",
    "\n",
    "            for epoch in range(NUM_EPOCHS):\n",
    "                model.train()\n",
    "                total_loss = 0.0\n",
    "                \n",
    "                for i, (masked, original) in enumerate(dataloader):\n",
    "                    masked, original = masked.to(device), original.to(device)\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(masked)\n",
    "                    loss = criterion(outputs, original)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    scheduler.step()\n",
    "                    \n",
    "                    total_loss += loss.item()\n",
    "\n",
    "                print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}] Loss: {total_loss/len(dataloader):.4f}\")\n",
    "\n",
    "            torch.save(model.get_backbone().state_dict(), \"ds_mae_backbone_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37de4197-4d2f-45d4-ae86-314f63acf3a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO11n-cls-shuffle summary: 92 layers, 1,540,263 parameters, 1,540,263 gradients, 3.3 GFLOPs\n",
      "æ­£åœ¨è¼‰å…¥ DS-MAE é è¨“ç·´æ¬Šé‡: ds_mae_backbone_weights.pth ...\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.0.conv.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.0.bn.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.0.bn.bias\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.0.bn.running_mean\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.0.bn.running_var\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.1.conv.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.1.bn.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.1.bn.bias\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.1.bn.running_mean\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.1.bn.running_var\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.2.cv1.conv.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.2.cv1.bn.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.2.cv1.bn.bias\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.2.cv1.bn.running_mean\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.2.cv1.bn.running_var\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.2.cv2.conv.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.2.cv2.bn.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.2.cv2.bn.bias\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.2.cv2.bn.running_mean\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.2.cv2.bn.running_var\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.2.m.0.cv1.conv.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.2.m.0.cv1.bn.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.2.m.0.cv1.bn.bias\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.2.m.0.cv1.bn.running_mean\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.2.m.0.cv1.bn.running_var\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.2.m.0.cv2.conv.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.2.m.0.cv2.bn.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.2.m.0.cv2.bn.bias\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.2.m.0.cv2.bn.running_mean\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.2.m.0.cv2.bn.running_var\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.3.conv.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.3.bn.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.3.bn.bias\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.3.bn.running_mean\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.3.bn.running_var\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.4.cv1.conv.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.4.cv1.bn.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.4.cv1.bn.bias\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.4.cv1.bn.running_mean\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.4.cv1.bn.running_var\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.4.cv2.conv.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.4.cv2.bn.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.4.cv2.bn.bias\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.4.cv2.bn.running_mean\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.4.cv2.bn.running_var\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.4.m.0.cv1.conv.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.4.m.0.cv1.bn.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.4.m.0.cv1.bn.bias\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.4.m.0.cv1.bn.running_mean\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.4.m.0.cv1.bn.running_var\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.4.m.0.cv2.conv.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.4.m.0.cv2.bn.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.4.m.0.cv2.bn.bias\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.4.m.0.cv2.bn.running_mean\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.4.m.0.cv2.bn.running_var\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.5.conv.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.5.bn.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.5.bn.bias\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.5.bn.running_mean\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.5.bn.running_var\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.6.cv1.conv.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.6.cv1.bn.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.6.cv1.bn.bias\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.6.cv1.bn.running_mean\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.6.cv1.bn.running_var\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.6.cv2.conv.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.6.cv2.bn.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.6.cv2.bn.bias\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.6.cv2.bn.running_mean\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.6.cv2.bn.running_var\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.6.m.0.cv1.conv.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.6.m.0.cv1.bn.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.6.m.0.cv1.bn.bias\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.6.m.0.cv1.bn.running_mean\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.6.m.0.cv1.bn.running_var\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.6.m.0.cv2.conv.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.6.m.0.cv2.bn.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.6.m.0.cv2.bn.bias\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.6.m.0.cv2.bn.running_mean\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.6.m.0.cv2.bn.running_var\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.6.m.0.cv3.conv.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.6.m.0.cv3.bn.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.6.m.0.cv3.bn.bias\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.6.m.0.cv3.bn.running_mean\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.6.m.0.cv3.bn.running_var\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.6.m.0.m.0.cv1.conv.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.6.m.0.m.0.cv1.bn.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.6.m.0.m.0.cv1.bn.bias\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.6.m.0.m.0.cv1.bn.running_mean\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.6.m.0.m.0.cv1.bn.running_var\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.6.m.0.m.0.cv2.conv.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.6.m.0.m.0.cv2.bn.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.6.m.0.m.0.cv2.bn.bias\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.6.m.0.m.0.cv2.bn.running_mean\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.6.m.0.m.0.cv2.bn.running_var\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.6.m.0.m.1.cv1.conv.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.6.m.0.m.1.cv1.bn.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.6.m.0.m.1.cv1.bn.bias\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.6.m.0.m.1.cv1.bn.running_mean\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.6.m.0.m.1.cv1.bn.running_var\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.6.m.0.m.1.cv2.conv.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.6.m.0.m.1.cv2.bn.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.6.m.0.m.1.cv2.bn.bias\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.6.m.0.m.1.cv2.bn.running_mean\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.6.m.0.m.1.cv2.bn.running_var\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.7.conv.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.7.bn.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.7.bn.bias\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.7.bn.running_mean\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.7.bn.running_var\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.8.cv1.conv.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.8.cv1.bn.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.8.cv1.bn.bias\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.8.cv1.bn.running_mean\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.8.cv1.bn.running_var\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.8.cv2.conv.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.8.cv2.bn.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.8.cv2.bn.bias\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.8.cv2.bn.running_mean\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.8.cv2.bn.running_var\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.8.m.0.cv1.conv.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.8.m.0.cv1.bn.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.8.m.0.cv1.bn.bias\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.8.m.0.cv1.bn.running_mean\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.8.m.0.cv1.bn.running_var\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.8.m.0.cv2.conv.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.8.m.0.cv2.bn.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.8.m.0.cv2.bn.bias\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.8.m.0.cv2.bn.running_mean\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.8.m.0.cv2.bn.running_var\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.8.m.0.cv3.conv.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.8.m.0.cv3.bn.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.8.m.0.cv3.bn.bias\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.8.m.0.cv3.bn.running_mean\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.8.m.0.cv3.bn.running_var\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.8.m.0.m.0.cv1.conv.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.8.m.0.m.0.cv1.bn.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.8.m.0.m.0.cv1.bn.bias\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.8.m.0.m.0.cv1.bn.running_mean\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.8.m.0.m.0.cv1.bn.running_var\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.8.m.0.m.0.cv2.conv.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.8.m.0.m.0.cv2.bn.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.8.m.0.m.0.cv2.bn.bias\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.8.m.0.m.0.cv2.bn.running_mean\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.8.m.0.m.0.cv2.bn.running_var\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.8.m.0.m.1.cv1.conv.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.8.m.0.m.1.cv1.bn.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.8.m.0.m.1.cv1.bn.bias\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.8.m.0.m.1.cv1.bn.running_mean\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.8.m.0.m.1.cv1.bn.running_var\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.8.m.0.m.1.cv2.conv.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.8.m.0.m.1.cv2.bn.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.8.m.0.m.1.cv2.bn.bias\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.8.m.0.m.1.cv2.bn.running_mean\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.8.m.0.m.1.cv2.bn.running_var\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.9.cv1.conv.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.9.cv2.conv.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.9.cv2.bn.weight\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.9.cv2.bn.bias\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.9.cv2.bn.running_mean\n",
      "è·³éå½¢ç‹€ä¸ç¬¦å±¤: model.9.cv2.bn.running_var\n",
      "æˆåŠŸè¼‰å…¥ 37 å±¤ DS-MAE æ¬Šé‡ï¼\n",
      "Ultralytics 8.3.78 ğŸš€ Python-3.12.2 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX A5000, 24130MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolo11n-cls-shuffle.yaml, data=/home/hank52052/Dataset/isic/HAM10000/Four_Classes, epochs=1200, time=None, patience=40, batch=64, imgsz=256, save=True, save_period=-1, cache=False, device=None, workers=8, project=/home/hank52052/code/isic/yolo_training, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.8, hsv_s=0.8, hsv_v=0.9, degrees=0.95, translate=0.8, scale=0.9, shear=0.8, perspective=0.0, flipud=0.9, fliplr=0.9, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/home/hank52052/code/isic/yolo_training/train2\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /home/hank52052/Dataset/isic/HAM10000/Four_Classes/train... found 36712 images in 4 classes âœ… \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /home/hank52052/Dataset/isic/HAM10000/Four_Classes/val... found 193 images in 4 classes âœ… \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /home/hank52052/Dataset/isic/HAM10000/Four_Classes/test... found 1512 images in 4 classes âœ… \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764750128.426576  383924 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764750128.432567  383924 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1764750128.447318  383924 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764750128.447336  383924 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764750128.447338  383924 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764750128.447339  383924 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=7 with nc=4\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 10                  -1  2       192  ultralytics.nn.modules.block.ShuffleAttention[256, 256]                    \n",
      " 11                  -1  1    335364  ultralytics.nn.modules.head.Classify         [256, 4]                      \n",
      "YOLO11n-cls-shuffle summary: 92 layers, 1,536,420 parameters, 1,536,420 gradients, 3.3 GFLOPs\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /home/hank52052/code/isic/yolo_training/train2', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/hank52052/Dataset/isic/HAM10000/Four_Classes/train... 36712 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36712/36712 [00:06<00:00, 5939.65it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/hank52052/Dataset/isic/HAM10000/Four_Classes/train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/hank52052/Dataset/isic/HAM10000/Four_Classes/val... 193 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 193/193 [00:00<00:00, 4334.35it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/hank52052/Dataset/isic/HAM10000/Four_Classes/val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 41 weight(decay=0.0), 44 weight(decay=0.0005), 46 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 256 train, 256 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/hank52052/code/isic/yolo_training/train2\u001b[0m\n",
      "Starting training for 1200 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     1/1200      1.23G      1.318         40        256: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 574/574 [00:45<00:00, 12.69it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.575          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     2/1200      1.09G      1.195         40        256: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 574/574 [00:44<00:00, 12.94it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 54.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.254          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     3/1200      1.11G      1.009         40        256: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 574/574 [00:44<00:00, 12.94it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 54.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.694          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     4/1200      1.11G     0.9194         64        256:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 310/574 [00:23<00:20, 13.06it/s]\n",
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f3247b92f30>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hank52052/anaconda3/envs/yolo_old/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "KeyboardInterrupt: \n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "ds_mae_weights_path = \"ds_mae_backbone_weights.pth\" \n",
    "custom_yaml_path = 'yolo11s-cls-shuffle.yaml'\n",
    "\n",
    "model = YOLO(custom_yaml_path)\n",
    "\n",
    "print(f\"[INFO] Loading DS-MAE pretrained backbone weights from: {ds_mae_weights_path}...\")\n",
    "\n",
    "ds_mae_state_dict = torch.load(ds_mae_weights_path)\n",
    "current_model_dict = model.model.state_dict()\n",
    "new_state_dict = {}\n",
    "\n",
    "for k, v in ds_mae_state_dict.items():\n",
    "    target_key = f\"model.{k}\"\n",
    "    \n",
    "    if target_key in current_model_dict:\n",
    "        if current_model_dict[target_key].shape == v.shape:\n",
    "            new_state_dict[target_key] = v\n",
    "        else:\n",
    "            print(f\"[WARNING] Skipping layer due to shape mismatch: {target_key}\")\n",
    "    else:\n",
    "        print(f\"[WARNING] Skipping unknown layer: {target_key}\")\n",
    "\n",
    "model.model.load_state_dict(new_state_dict, strict=False)\n",
    "print(f\"[INFO] Successfully loaded {len(new_state_dict)} layers from DS-MAE backbone.\")\n",
    "\n",
    "results = model.train(\n",
    "    data=\"/home/hank52052/Dataset/isic/HAM10000/Four_Classes\",\n",
    "    project=\"/home/hank52052/code/isic/yolo_training\",\n",
    "    epochs=1200,\n",
    "    imgsz=256,\n",
    "    batch=64,\n",
    "    patience=40,\n",
    "    plots=True,\n",
    "    \n",
    "    # Augmentation Hyperparameters\n",
    "    degrees=0.95, \n",
    "    scale=0.9, \n",
    "    shear=0.8, \n",
    "    flipud=0.9, \n",
    "    fliplr=0.9,\n",
    "    hsv_h=0.8, \n",
    "    hsv_s=0.8, \n",
    "    hsv_v=0.9, \n",
    "    translate=0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc9517b1-fb95-4efa-938b-4b304cd96149",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO11n-cls-shuffle summary: 92 layers, 1,540,263 parameters, 1,540,263 gradients, 3.3 GFLOPs\n",
      "æ­£åœ¨è¼‰å…¥ç¬¬ä¸€éšæ®µ(å››åˆ†é¡)æ¬Šé‡: /home/hank52052/code/isic/yolo_training/train/weights/best.pt ...\n",
      "âš ï¸ è­¦å‘Š: ç„¡æ³•è¼‰å…¥å››åˆ†é¡æ¬Šé‡ (Error(s) in loading state_dict for ClassificationModel:\n",
      "\tsize mismatch for model.0.conv.weight: copying a param with shape torch.Size([32, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 3, 3, 3]).\n",
      "\tsize mismatch for model.0.bn.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n",
      "\tsize mismatch for model.0.bn.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n",
      "\tsize mismatch for model.0.bn.running_mean: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n",
      "\tsize mismatch for model.0.bn.running_var: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n",
      "\tsize mismatch for model.1.conv.weight: copying a param with shape torch.Size([64, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 16, 3, 3]).\n",
      "\tsize mismatch for model.1.bn.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for model.1.bn.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for model.1.bn.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for model.1.bn.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for model.2.cv1.conv.weight: copying a param with shape torch.Size([64, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 32, 1, 1]).\n",
      "\tsize mismatch for model.2.cv1.bn.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for model.2.cv1.bn.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for model.2.cv1.bn.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for model.2.cv1.bn.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for model.2.cv2.conv.weight: copying a param with shape torch.Size([128, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 48, 1, 1]).\n",
      "\tsize mismatch for model.2.cv2.bn.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for model.2.cv2.bn.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for model.2.cv2.bn.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for model.2.cv2.bn.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for model.2.m.0.cv1.conv.weight: copying a param with shape torch.Size([16, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([8, 16, 3, 3]).\n",
      "\tsize mismatch for model.2.m.0.cv1.bn.weight: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([8]).\n",
      "\tsize mismatch for model.2.m.0.cv1.bn.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([8]).\n",
      "\tsize mismatch for model.2.m.0.cv1.bn.running_mean: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([8]).\n",
      "\tsize mismatch for model.2.m.0.cv1.bn.running_var: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([8]).\n",
      "\tsize mismatch for model.2.m.0.cv2.conv.weight: copying a param with shape torch.Size([32, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 8, 3, 3]).\n",
      "\tsize mismatch for model.2.m.0.cv2.bn.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n",
      "\tsize mismatch for model.2.m.0.cv2.bn.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n",
      "\tsize mismatch for model.2.m.0.cv2.bn.running_mean: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n",
      "\tsize mismatch for model.2.m.0.cv2.bn.running_var: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n",
      "\tsize mismatch for model.3.conv.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n",
      "\tsize mismatch for model.3.bn.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for model.3.bn.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for model.3.bn.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for model.3.bn.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for model.4.cv1.conv.weight: copying a param with shape torch.Size([128, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n",
      "\tsize mismatch for model.4.cv1.bn.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for model.4.cv1.bn.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for model.4.cv1.bn.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for model.4.cv1.bn.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for model.4.cv2.conv.weight: copying a param with shape torch.Size([256, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 96, 1, 1]).\n",
      "\tsize mismatch for model.4.cv2.bn.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "\tsize mismatch for model.4.cv2.bn.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "\tsize mismatch for model.4.cv2.bn.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "\tsize mismatch for model.4.cv2.bn.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "\tsize mismatch for model.4.m.0.cv1.conv.weight: copying a param with shape torch.Size([32, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 32, 3, 3]).\n",
      "\tsize mismatch for model.4.m.0.cv1.bn.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n",
      "\tsize mismatch for model.4.m.0.cv1.bn.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n",
      "\tsize mismatch for model.4.m.0.cv1.bn.running_mean: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n",
      "\tsize mismatch for model.4.m.0.cv1.bn.running_var: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([16]).\n",
      "\tsize mismatch for model.4.m.0.cv2.conv.weight: copying a param with shape torch.Size([64, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 16, 3, 3]).\n",
      "\tsize mismatch for model.4.m.0.cv2.bn.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for model.4.m.0.cv2.bn.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for model.4.m.0.cv2.bn.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for model.4.m.0.cv2.bn.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for model.5.conv.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n",
      "\tsize mismatch for model.5.bn.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "\tsize mismatch for model.5.bn.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "\tsize mismatch for model.5.bn.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "\tsize mismatch for model.5.bn.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "\tsize mismatch for model.6.cv1.conv.weight: copying a param with shape torch.Size([256, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1]).\n",
      "\tsize mismatch for model.6.cv1.bn.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "\tsize mismatch for model.6.cv1.bn.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "\tsize mismatch for model.6.cv1.bn.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "\tsize mismatch for model.6.cv1.bn.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "\tsize mismatch for model.6.cv2.conv.weight: copying a param with shape torch.Size([256, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 192, 1, 1]).\n",
      "\tsize mismatch for model.6.cv2.bn.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "\tsize mismatch for model.6.cv2.bn.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "\tsize mismatch for model.6.cv2.bn.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "\tsize mismatch for model.6.cv2.bn.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "\tsize mismatch for model.6.m.0.cv1.conv.weight: copying a param with shape torch.Size([64, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 64, 1, 1]).\n",
      "\tsize mismatch for model.6.m.0.cv1.bn.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for model.6.m.0.cv1.bn.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for model.6.m.0.cv1.bn.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for model.6.m.0.cv1.bn.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for model.6.m.0.cv2.conv.weight: copying a param with shape torch.Size([64, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 64, 1, 1]).\n",
      "\tsize mismatch for model.6.m.0.cv2.bn.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for model.6.m.0.cv2.bn.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for model.6.m.0.cv2.bn.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for model.6.m.0.cv2.bn.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for model.6.m.0.cv3.conv.weight: copying a param with shape torch.Size([128, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n",
      "\tsize mismatch for model.6.m.0.cv3.bn.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for model.6.m.0.cv3.bn.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for model.6.m.0.cv3.bn.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for model.6.m.0.cv3.bn.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for model.6.m.0.m.0.cv1.conv.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 32, 3, 3]).\n",
      "\tsize mismatch for model.6.m.0.m.0.cv1.bn.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for model.6.m.0.m.0.cv1.bn.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for model.6.m.0.m.0.cv1.bn.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for model.6.m.0.m.0.cv1.bn.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for model.6.m.0.m.0.cv2.conv.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 32, 3, 3]).\n",
      "\tsize mismatch for model.6.m.0.m.0.cv2.bn.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for model.6.m.0.m.0.cv2.bn.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for model.6.m.0.m.0.cv2.bn.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for model.6.m.0.m.0.cv2.bn.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for model.6.m.0.m.1.cv1.conv.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 32, 3, 3]).\n",
      "\tsize mismatch for model.6.m.0.m.1.cv1.bn.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for model.6.m.0.m.1.cv1.bn.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for model.6.m.0.m.1.cv1.bn.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for model.6.m.0.m.1.cv1.bn.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for model.6.m.0.m.1.cv2.conv.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 32, 3, 3]).\n",
      "\tsize mismatch for model.6.m.0.m.1.cv2.bn.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for model.6.m.0.m.1.cv2.bn.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for model.6.m.0.m.1.cv2.bn.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for model.6.m.0.m.1.cv2.bn.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for model.7.conv.weight: copying a param with shape torch.Size([512, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 128, 3, 3]).\n",
      "\tsize mismatch for model.7.bn.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "\tsize mismatch for model.7.bn.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "\tsize mismatch for model.7.bn.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "\tsize mismatch for model.7.bn.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "\tsize mismatch for model.8.cv1.conv.weight: copying a param with shape torch.Size([512, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1]).\n",
      "\tsize mismatch for model.8.cv1.bn.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "\tsize mismatch for model.8.cv1.bn.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "\tsize mismatch for model.8.cv1.bn.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "\tsize mismatch for model.8.cv1.bn.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "\tsize mismatch for model.8.cv2.conv.weight: copying a param with shape torch.Size([512, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 384, 1, 1]).\n",
      "\tsize mismatch for model.8.cv2.bn.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "\tsize mismatch for model.8.cv2.bn.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "\tsize mismatch for model.8.cv2.bn.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "\tsize mismatch for model.8.cv2.bn.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "\tsize mismatch for model.8.m.0.cv1.conv.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 128, 1, 1]).\n",
      "\tsize mismatch for model.8.m.0.cv1.bn.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for model.8.m.0.cv1.bn.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for model.8.m.0.cv1.bn.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for model.8.m.0.cv1.bn.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for model.8.m.0.cv2.conv.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 128, 1, 1]).\n",
      "\tsize mismatch for model.8.m.0.cv2.bn.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for model.8.m.0.cv2.bn.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for model.8.m.0.cv2.bn.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for model.8.m.0.cv2.bn.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for model.8.m.0.cv3.conv.weight: copying a param with shape torch.Size([256, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1]).\n",
      "\tsize mismatch for model.8.m.0.cv3.bn.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "\tsize mismatch for model.8.m.0.cv3.bn.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "\tsize mismatch for model.8.m.0.cv3.bn.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "\tsize mismatch for model.8.m.0.cv3.bn.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "\tsize mismatch for model.8.m.0.m.0.cv1.conv.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n",
      "\tsize mismatch for model.8.m.0.m.0.cv1.bn.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for model.8.m.0.m.0.cv1.bn.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for model.8.m.0.m.0.cv1.bn.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for model.8.m.0.m.0.cv1.bn.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for model.8.m.0.m.0.cv2.conv.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n",
      "\tsize mismatch for model.8.m.0.m.0.cv2.bn.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for model.8.m.0.m.0.cv2.bn.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for model.8.m.0.m.0.cv2.bn.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for model.8.m.0.m.0.cv2.bn.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for model.8.m.0.m.1.cv1.conv.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n",
      "\tsize mismatch for model.8.m.0.m.1.cv1.bn.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for model.8.m.0.m.1.cv1.bn.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for model.8.m.0.m.1.cv1.bn.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for model.8.m.0.m.1.cv1.bn.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for model.8.m.0.m.1.cv2.conv.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n",
      "\tsize mismatch for model.8.m.0.m.1.cv2.bn.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for model.8.m.0.m.1.cv2.bn.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for model.8.m.0.m.1.cv2.bn.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for model.8.m.0.m.1.cv2.bn.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
      "\tsize mismatch for model.9.cv1.conv.weight: copying a param with shape torch.Size([512, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1]).\n",
      "\tsize mismatch for model.9.cv1.bn.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "\tsize mismatch for model.9.cv1.bn.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "\tsize mismatch for model.9.cv1.bn.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "\tsize mismatch for model.9.cv1.bn.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "\tsize mismatch for model.9.cv2.conv.weight: copying a param with shape torch.Size([512, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1]).\n",
      "\tsize mismatch for model.9.cv2.bn.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "\tsize mismatch for model.9.cv2.bn.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "\tsize mismatch for model.9.cv2.bn.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "\tsize mismatch for model.9.cv2.bn.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "\tsize mismatch for model.9.m.0.attn.qkv.conv.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 128, 1, 1]).\n",
      "\tsize mismatch for model.9.m.0.attn.qkv.bn.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "\tsize mismatch for model.9.m.0.attn.qkv.bn.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "\tsize mismatch for model.9.m.0.attn.qkv.bn.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "\tsize mismatch for model.9.m.0.attn.qkv.bn.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "\tsize mismatch for model.9.m.0.attn.proj.conv.weight: copying a param with shape torch.Size([256, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1]).\n",
      "\tsize mismatch for model.9.m.0.attn.proj.bn.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "\tsize mismatch for model.9.m.0.attn.proj.bn.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "\tsize mismatch for model.9.m.0.attn.proj.bn.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "\tsize mismatch for model.9.m.0.attn.proj.bn.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "\tsize mismatch for model.9.m.0.attn.pe.conv.weight: copying a param with shape torch.Size([256, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 1, 3, 3]).\n",
      "\tsize mismatch for model.9.m.0.attn.pe.bn.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "\tsize mismatch for model.9.m.0.attn.pe.bn.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "\tsize mismatch for model.9.m.0.attn.pe.bn.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "\tsize mismatch for model.9.m.0.attn.pe.bn.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "\tsize mismatch for model.9.m.0.ffn.0.conv.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 128, 1, 1]).\n",
      "\tsize mismatch for model.9.m.0.ffn.0.bn.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "\tsize mismatch for model.9.m.0.ffn.0.bn.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "\tsize mismatch for model.9.m.0.ffn.0.bn.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "\tsize mismatch for model.9.m.0.ffn.0.bn.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "\tsize mismatch for model.9.m.0.ffn.1.conv.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n",
      "\tsize mismatch for model.9.m.0.ffn.1.bn.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "\tsize mismatch for model.9.m.0.ffn.1.bn.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "\tsize mismatch for model.9.m.0.ffn.1.bn.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
      "\tsize mismatch for model.9.m.0.ffn.1.bn.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).)\n",
      "å°‡ä½¿ç”¨éš¨æ©Ÿåˆå§‹åŒ–æˆ–è«‹æ‰‹å‹•æŒ‡å®šæ­£ç¢ºè·¯å¾‘ã€‚\n",
      "Ultralytics 8.3.78 ğŸš€ Python-3.12.2 torch-2.6.0+cu124 CUDA:0 (NVIDIA RTX A5000, 24130MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolo11n-cls-shuffle.yaml, data=/home/hank52052/Dataset/isic/HAM10000/Original_Classes, epochs=1200, time=None, patience=40, batch=64, imgsz=256, save=True, save_period=-1, cache=False, device=None, workers=8, project=/home/hank52052/code/isic/yolo_training, name=seven_classes_finetune, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=True, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.8, hsv_s=0.8, hsv_v=0.9, degrees=0.95, translate=0.8, scale=0.9, shear=0.8, perspective=0.0, flipud=0.9, fliplr=0.9, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/home/hank52052/code/isic/yolo_training/seven_classes_finetune\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /home/hank52052/Dataset/isic/HAM10000/Original_Classes/train... found 52878 images in 7 classes âœ… \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /home/hank52052/Dataset/isic/HAM10000/Original_Classes/val... found 193 images in 7 classes âœ… \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /home/hank52052/Dataset/isic/HAM10000/Original_Classes/test... found 1512 images in 7 classes âœ… \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764750320.996880  388570 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764750321.003027  388570 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1764750321.018048  388570 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764750321.018065  388570 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764750321.018067  388570 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764750321.018069  388570 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 10                  -1  2       192  ultralytics.nn.modules.block.ShuffleAttention[256, 256]                    \n",
      " 11                  -1  1    339207  ultralytics.nn.modules.head.Classify         [256, 7]                      \n",
      "YOLO11n-cls-shuffle summary: 92 layers, 1,540,263 parameters, 1,540,263 gradients, 3.3 GFLOPs\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /home/hank52052/code/isic/yolo_training/seven_classes_finetune', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "custom_yaml_path = 'yolo11s-cls-shuffle.yaml'\n",
    "model = YOLO(custom_yaml_path)\n",
    "\n",
    "stage1_weights_path = \"/home/hank52052/code/isic/yolo_training/train/weights/best.pt\"\n",
    "\n",
    "print(f\"[INFO] Loading Stage 1 pretrained weights from: {stage1_weights_path}...\")\n",
    "\n",
    "try:\n",
    "    stage1_model = YOLO(stage1_weights_path)\n",
    "    model.model.load_state_dict(stage1_model.model.state_dict(), strict=False)\n",
    "    print(\"[INFO] Successfully loaded backbone weights. Classification head initialized for 7-class fine-grained task.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"[WARNING] Failed to load Stage 1 weights: {e}\")\n",
    "    print(\"[INFO] Proceeding with random initialization.\")\n",
    "\n",
    "results = model.train(\n",
    "    data=\"/home/hank52052/Dataset/isic/HAM10000/Original_Classes\",\n",
    "    project=\"/home/hank52052/code/isic/yolo_training\",\n",
    "    name=\"seven_classes_finetune\",\n",
    "    epochs=1200,\n",
    "    imgsz=256,\n",
    "    patience=40,\n",
    "    batch=64,\n",
    "    rect=True,\n",
    "    plots=True,\n",
    "    \n",
    "    degrees=0.95, \n",
    "    scale=0.9, \n",
    "    shear=0.8, \n",
    "    flipud=0.9, \n",
    "    fliplr=0.9,\n",
    "    hsv_h=0.8, \n",
    "    hsv_s=0.8, \n",
    "    hsv_v=0.9, \n",
    "    translate=0.8,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
